{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook processes CAFE c2_restart ocean daily data for building climatologies. Only the last 100 years are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T00:16:01.994302Z",
     "start_time": "2018-06-20T00:15:56.681462Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import packages -----\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from ipywidgets import FloatProgress\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T00:16:05.558937Z",
     "start_time": "2018-06-20T00:16:05.410716Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_CAFE</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sst</td>\n",
       "      <td>sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patm_t</td>\n",
       "      <td>patm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eta_t</td>\n",
       "      <td>eta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sss</td>\n",
       "      <td>sss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u_surf</td>\n",
       "      <td>u_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>v_surf</td>\n",
       "      <td>v_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mld</td>\n",
       "      <td>mld</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name_CAFE name_std\n",
       "0       sst      sst\n",
       "1    patm_t     patm\n",
       "2     eta_t      eta\n",
       "3       sss      sss\n",
       "4    u_surf      u_s\n",
       "5    v_surf      v_s\n",
       "6       mld      mld"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard naming -----\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['sst', 'patm_t', 'eta_t', 'sss', 'u_surf', 'v_surf', 'mld'],\n",
    "         'name_std' : ['sst', 'patm',   'eta',   'sss', 'u_s',    'v_s',    'mld']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only use last 50 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T00:17:50.250594Z",
     "start_time": "2018-06-20T00:16:12.384618Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/coding/times.py:132: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy cftime.datetime objects instead, reason: dates out of range\n",
      "  enable_cftimeindex)\n",
      "/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/coding/variables.py:66: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy cftime.datetime objects instead, reason: dates out of range\n",
      "  return self.func(self.array[key])\n"
     ]
    }
   ],
   "source": [
    "# Loop over all paths -----\n",
    "base = '/OSM/CBR/OA_DCFP/data2/model_output/CAFE/controls/c2_restart/'\n",
    "years = range(500,550)\n",
    "\n",
    "paths = []\n",
    "for year in years:\n",
    "    path = base + 'ocean_daily_0' + str(year) + '_01_01.nc'\n",
    "    paths.append(path)\n",
    "\n",
    "ds = xr.open_mfdataset(paths, autoclose=True) \\\n",
    "       .drop(['average_T1','average_T2','average_DT','time_bounds',\n",
    "              'area_t','area_u','geolat_c','geolat_t','ht','mld_sq']) \\\n",
    "       .rename(name_dict)\n",
    "        \n",
    "if 'xu_ocean' in ds.dims:\n",
    "    ds = ds.rename({'xu_ocean':'lon_2','yu_ocean':'lat_2'})\n",
    "if 'xt_ocean' in ds.dims:\n",
    "    ds = ds.rename({'xt_ocean':'lon','yt_ocean':'lat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T00:17:50.252179Z",
     "start_time": "2018-06-20T00:16:22.074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (lat: 300, lat_2: 300, lon: 360, lon_2: 360, nv: 2, time: 18250)\n",
       "Coordinates:\n",
       "  * lon      (lon) float64 -279.5 -278.5 -277.5 -276.5 -275.5 -274.5 -273.5 ...\n",
       "  * lat      (lat) float64 -77.88 -77.63 -77.38 -77.13 -76.88 -76.63 -76.37 ...\n",
       "  * nv       (nv) float64 1.0 2.0\n",
       "  * lon_2    (lon_2) float64 -279.0 -278.0 -277.0 -276.0 -275.0 -274.0 ...\n",
       "  * lat_2    (lat_2) float64 -77.75 -77.51 -77.26 -77.01 -76.75 -76.5 -76.24 ...\n",
       "  * time     (time) object  500-01-01 12:00:00  500-01-02 12:00:00 ...\n",
       "Data variables:\n",
       "    patm     (time, lat, lon) float32 dask.array<shape=(18250, 300, 360), chunksize=(365, 300, 360)>\n",
       "    eta      (time, lat, lon) float32 dask.array<shape=(18250, 300, 360), chunksize=(365, 300, 360)>\n",
       "    sss      (time, lat, lon) float32 dask.array<shape=(18250, 300, 360), chunksize=(365, 300, 360)>\n",
       "    sst      (time, lat, lon) float32 dask.array<shape=(18250, 300, 360), chunksize=(365, 300, 360)>\n",
       "    u_s      (time, lat_2, lon_2) float32 dask.array<shape=(18250, 300, 360), chunksize=(365, 300, 360)>\n",
       "    v_s      (time, lat_2, lon_2) float32 dask.array<shape=(18250, 300, 360), chunksize=(365, 300, 360)>\n",
       "    mld      (time, lat, lon) float32 dask.array<shape=(18250, 300, 360), chunksize=(365, 300, 360)>\n",
       "Attributes:\n",
       "    filename:   ocean_daily_0500_01_01.nc\n",
       "    title:      AccessOcean-AM2\n",
       "    grid_type:  mosaic\n",
       "    grid_tile:  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:48:52.563614Z",
     "start_time": "2018-06-15T00:48:44.889863Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Use year 2016 as time -----\n",
    "path = '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2016/mn1/OUTPUT.1/ocean_daily*.nc'\n",
    "dataset = xr.open_mfdataset(path, autoclose=True)\n",
    "time_use = xr.concat([dataset.time[:59], dataset.time[60:366]],dim='time')\n",
    "time_ly = dataset.time[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:49:46.347817Z",
     "start_time": "2018-06-15T00:48:52.567253Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Make month_day array of month-day -----\n",
    "m = [str(ds.time.values[i].timetuple()[1]).zfill(2) + '-' for i in range(len(ds.time))]\n",
    "d = [str(ds.time.values[i].timetuple()[2]).zfill(2) for i in range(len(ds.time))]\n",
    "md = np.core.defchararray.add(m, d)\n",
    "\n",
    "# Replace time array with month_day array and groupby -----\n",
    "ds['time'] = md\n",
    "clim = ds.groupby('time').mean(dim='time',keep_attrs=True)\n",
    "clim['time'] = time_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:49:46.435074Z",
     "start_time": "2018-06-15T00:49:46.351624Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Replicate Feb 28th as Feb 29th to deal with leap years -----\n",
    "clim_ly = clim.copy().sel(time='2016-02-28')\n",
    "clim_ly['time'] = np.array([time_ly.values])\n",
    "clim = xr.auto_combine([clim,clim_ly]).sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T01:18:53.245104Z",
     "start_time": "2018-06-15T00:49:46.438411Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: b'/OSM/CBR/OA_DCFP/data/intermediate_products/pylatte_climatologies/cafe.c2.ocean.500_549.clim.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8933f6056ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m clim.to_netcdf(save_fldr + 'cafe.c2.ocean.500_549.clim.nc', mode = 'w',\n\u001b[1;32m      4\u001b[0m                encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n\u001b[0;32m----> 5\u001b[0;31m                            'units':'days since 0001-01-01 00:00:00'}})\n\u001b[0m",
      "\u001b[0;32m/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                          \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                          \u001b[0munlimited_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munlimited_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                          compute=compute)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     def to_zarr(self, store=None, mode='w-', synchronizer=None, group=None,\n",
      "\u001b[0;32m/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, writer, encoding, unlimited_dims, compute)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_or_file\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath_or_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     store = store_open(target, mode, format, group, writer,\n\u001b[0;32m--> 714\u001b[0;31m                        autoclose=autoclose, lock=lock)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munlimited_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, writer, clobber, diskless, persist, autoclose, lock)\u001b[0m\n\u001b[1;32m    330\u001b[0m                                    \u001b[0mdiskless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiskless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                                    format=format)\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         return cls(ds, mode=mode, writer=writer, opener=opener,\n\u001b[1;32m    334\u001b[0m                    autoclose=autoclose, lock=lock)\n",
      "\u001b[0;32m/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_open_netcdf4_group\u001b[0;34m(filename, mode, group, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: b'/OSM/CBR/OA_DCFP/data/intermediate_products/pylatte_climatologies/cafe.c2.ocean.500_549.clim.nc'"
     ]
    }
   ],
   "source": [
    "# Save the climatology -----\n",
    "save_fldr = '/OSM/CBR/OA_DCFP/data/intermediate_products/pylatte_climatologies/'\n",
    "clim.to_netcdf(save_fldr + 'cafe.c2.ocean.500_549.clim.nc', mode = 'w',\n",
    "               encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n",
    "                           'units':'days since 0001-01-01 00:00:00'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scratch_env]",
   "language": "python",
   "name": "conda-env-scratch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
