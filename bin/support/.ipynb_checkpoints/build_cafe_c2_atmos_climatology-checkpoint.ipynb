{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook processes CAFE v2 atmospheric daily data for building climatologies. Only the last 100 years are used.\n",
    "Currently only runs on Raijin, as control run data not yet transferred to Canberra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T07:51:03.421327Z",
     "start_time": "2018-06-12T07:50:47.082626Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages -----\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from ipywidgets import FloatProgress\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_CAFE</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ucomp</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vcomp</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sphum</td>\n",
       "      <td>sphum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hght</td>\n",
       "      <td>gh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lwflx</td>\n",
       "      <td>lwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shflx</td>\n",
       "      <td>shf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tau_x</td>\n",
       "      <td>tau_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tau_y</td>\n",
       "      <td>tau_y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_ref</td>\n",
       "      <td>t_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>q_ref</td>\n",
       "      <td>q_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u_ref</td>\n",
       "      <td>u_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>v_ref</td>\n",
       "      <td>v_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t_surf</td>\n",
       "      <td>t_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>h500</td>\n",
       "      <td>h500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>precip</td>\n",
       "      <td>precip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lwdn_sfc</td>\n",
       "      <td>lwf_dn_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>olr</td>\n",
       "      <td>olr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>swdn_sfc</td>\n",
       "      <td>swf_dn_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>swup_toa</td>\n",
       "      <td>swf_up_toa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name_CAFE    name_std\n",
       "0      ucomp           u\n",
       "1      vcomp           v\n",
       "2       temp        temp\n",
       "3      sphum       sphum\n",
       "4       hght          gh\n",
       "5      lwflx         lwf\n",
       "6      shflx         shf\n",
       "7      tau_x       tau_x\n",
       "8      tau_y       tau_y\n",
       "9      t_ref       t_ref\n",
       "10     q_ref       q_ref\n",
       "11     u_ref       u_ref\n",
       "12     v_ref       v_ref\n",
       "13    t_surf         t_s\n",
       "14      h500        h500\n",
       "15    precip      precip\n",
       "16  lwdn_sfc    lwf_dn_s\n",
       "17       olr         olr\n",
       "18  swdn_sfc    swf_dn_s\n",
       "19  swup_toa  swf_up_toa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard naming -----\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['ucomp', 'vcomp', 'temp', 'sphum', 'hght', 'lwflx', 'shflx', 'tau_x', 'tau_y', 't_ref', \n",
    "                       'q_ref', 'u_ref', 'v_ref', 't_surf', 'h500', 'precip', 'lwdn_sfc', 'olr', \n",
    "                       'swdn_sfc', 'swup_toa'],\n",
    "         'name_std' : ['u',     'v',     'temp', 'sphum', 'gh',   'lwf',   'shf',   'tau_x', 'tau_y', 't_ref', \n",
    "                       'q_ref', 'u_ref', 'v_ref', 't_s',    'h500', 'precip', 'lwf_dn_s', 'olr', \n",
    "                       'swf_dn_s', 'swf_up_toa']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only use last 100 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T07:52:05.026523Z",
     "start_time": "2018-06-12T07:51:54.334817Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3/lib/python3.6/site-packages/xarray/conventions.py:416: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy netCDF4.datetime objects instead, reason: dates out of range\n",
      "  result = decode_cf_datetime(example_value, units, calendar)\n",
      "/g/data3/hh5/public/apps/miniconda3/envs/analysis3/lib/python3.6/site-packages/xarray/conventions.py:435: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy netCDF4.datetime objects instead, reason: dates out of range\n",
      "  calendar=self.calendar)\n"
     ]
    }
   ],
   "source": [
    "# Loop over all paths -----\n",
    "base = '/g/data1/v14/coupled_model/v2/OUTPUT/'\n",
    "years = range(400,500)\n",
    "\n",
    "paths = []\n",
    "for year in years:\n",
    "    path = base + 'atmos_daily_0' + str(year) + '_01_01.nc'\n",
    "    paths.append(path)\n",
    "\n",
    "ds = xr.open_mfdataset(paths, autoclose=True) \\\n",
    "       .drop(['average_T1','average_T2','average_DT','time_bounds']) \\\n",
    "       .rename(name_dict)\n",
    "        \n",
    "if 'latb' in ds.dims:\n",
    "    ds = ds.rename({'latb':'lat_2','lonb':'lon_2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Use year 2016 as time -----\n",
    "path = '/g/data1/v14/forecast/v1/yr2016/mn1/OUTPUT.1/atmos_daily*.nc'\n",
    "dataset = xr.open_mfdataset(path, autoclose=True)\n",
    "time_use = xr.concat([dataset.time[:59], dataset.time[60:366]],dim='time')\n",
    "time_ly = dataset.time[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Make month_day array of month-day -----\n",
    "m = [str(ds.time.values[i].timetuple()[1]).zfill(2) + '-' for i in range(len(ds.time))]\n",
    "d = [str(ds.time.values[i].timetuple()[2]).zfill(2) for i in range(len(ds.time))]\n",
    "md = np.core.defchararray.add(m, d)\n",
    "\n",
    "# Replace time array with month_day array and groupby -----\n",
    "ds['time'] = md\n",
    "clim = ds.groupby('time').mean(dim='time',keep_attrs=True)\n",
    "clim['time'] = time_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Replicate Feb 28th as Feb 29th to deal with leap years -----\n",
    "clim_ly = clim.copy().sel(time='2016-02-28')\n",
    "clim_ly['time'] = np.array([time_ly.values])\n",
    "clim = xr.auto_combine([clim,clim_ly]).sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save the climatology in two parts - VDI struggles with one -----\n",
    "save_fldr = '/g/data1/v14/squ027/tmp/'\n",
    "clim_p1 = clim[['u', 'v', 'temp', 'sphum']]\n",
    "clim_p2 = clim[['gh', 'lwf', 'shf', 'tau_x', 'tau_y', 't_ref', 'q_ref', 'u_ref', 'v_ref', \n",
    "                't_s', 'h500', 'precip', 'lwf_dn_s', 'olr', 'swf_dn_s', 'swf_up_toa']]\n",
    "clim_p1.to_netcdf(save_fldr + 'cafe.c2.atmos.400_499.clim.p1.nc', mode = 'w',\n",
    "               encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n",
    "                           'units':'days since 0001-01-01 00:00:00'}})\n",
    "clim_p2.to_netcdf(save_fldr + 'cafe.c2.atmos.400_499.clim.p2.nc', mode = 'w',\n",
    "               encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n",
    "                           'units':'days since 0001-01-01 00:00:00'}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scratch_env]",
   "language": "python",
   "name": "conda-env-scratch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
