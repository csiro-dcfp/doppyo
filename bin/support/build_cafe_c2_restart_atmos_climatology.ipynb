{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook processes CAFE c2_restart atmospheric daily data for building climatologies. Only the last 50 years are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:43:06.070705Z",
     "start_time": "2018-06-15T00:43:06.064514Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import packages -----\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from ipywidgets import FloatProgress\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:43:06.969367Z",
     "start_time": "2018-06-15T00:43:06.939174Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_CAFE</th>\n",
       "      <th>name_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ucomp</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vcomp</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>temp</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sphum</td>\n",
       "      <td>sphum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hght</td>\n",
       "      <td>gh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lwflx</td>\n",
       "      <td>lwf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>shflx</td>\n",
       "      <td>shf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tau_x</td>\n",
       "      <td>tau_x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tau_y</td>\n",
       "      <td>tau_y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t_ref</td>\n",
       "      <td>t_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>q_ref</td>\n",
       "      <td>q_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>u_ref</td>\n",
       "      <td>u_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>v_ref</td>\n",
       "      <td>v_ref</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t_surf</td>\n",
       "      <td>t_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t_ref_min</td>\n",
       "      <td>t_ref_min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t_ref_max</td>\n",
       "      <td>t_ref_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ps</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>h500</td>\n",
       "      <td>h500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>precip</td>\n",
       "      <td>precip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lwdn_sfc</td>\n",
       "      <td>lwf_dn_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>olr</td>\n",
       "      <td>olr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>swdn_sfc</td>\n",
       "      <td>swf_dn_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>swup_toa</td>\n",
       "      <td>swf_up_toa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name_CAFE    name_std\n",
       "0       ucomp           u\n",
       "1       vcomp           v\n",
       "2        temp        temp\n",
       "3       sphum       sphum\n",
       "4        hght          gh\n",
       "5       lwflx         lwf\n",
       "6       shflx         shf\n",
       "7       tau_x       tau_x\n",
       "8       tau_y       tau_y\n",
       "9       t_ref       t_ref\n",
       "10      q_ref       q_ref\n",
       "11      u_ref       u_ref\n",
       "12      v_ref       v_ref\n",
       "13     t_surf         t_s\n",
       "14  t_ref_min   t_ref_min\n",
       "15  t_ref_max   t_ref_max\n",
       "16         ps          ps\n",
       "17       h500        h500\n",
       "18     precip      precip\n",
       "19   lwdn_sfc    lwf_dn_s\n",
       "20        olr         olr\n",
       "21   swdn_sfc    swf_dn_s\n",
       "22   swup_toa  swf_up_toa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard naming -----\n",
    "fields = pd.DataFrame( \\\n",
    "        {'name_CAFE': ['ucomp', 'vcomp', 'temp', 'sphum', 'hght', 'lwflx', 'shflx', 'tau_x', 'tau_y', 't_ref', \n",
    "                       'q_ref', 'u_ref', 'v_ref', 't_surf', 't_ref_min', 't_ref_max', 'ps', 'h500', 'precip', 'lwdn_sfc', \n",
    "                       'olr', 'swdn_sfc', 'swup_toa'],\n",
    "         'name_std' : ['u',     'v',     'temp', 'sphum', 'gh',   'lwf',   'shf',   'tau_x', 'tau_y', 't_ref', \n",
    "                       'q_ref', 'u_ref', 'v_ref', 't_s',    't_ref_min', 't_ref_max', 'ps', 'h500', 'precip', 'lwf_dn_s', \n",
    "                       'olr', 'swf_dn_s', 'swf_up_toa']}\n",
    "                     )\n",
    "name_dict = fields.set_index('name_CAFE').to_dict()['name_std']\n",
    "\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only use last 50 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:47:54.696487Z",
     "start_time": "2018-06-15T00:43:08.042211Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/coding/times.py:132: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy cftime.datetime objects instead, reason: dates out of range\n",
      "  enable_cftimeindex)\n",
      "/OSM/CBR/OA_DCFP/apps/squ027/anaconda3/envs/scratch_env/lib/python3.6/site-packages/xarray/coding/variables.py:66: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using dummy cftime.datetime objects instead, reason: dates out of range\n",
      "  return self.func(self.array[key])\n"
     ]
    }
   ],
   "source": [
    "# Loop over all paths -----\n",
    "base = '/OSM/CBR/OA_DCFP/data2/model_output/CAFE/controls/c2_restart/OUTPUT/'\n",
    "years = range(500,550)\n",
    "\n",
    "paths = []\n",
    "for year in years:\n",
    "    path = base + 'atmos_daily_0' + str(year) + '_01_01.plevel.nc'\n",
    "    paths.append(path)\n",
    "\n",
    "ds = xr.open_mfdataset(paths, autoclose=True) \\\n",
    "       .drop(['average_T1','average_T2','average_DT','time_bounds']) \\\n",
    "       .rename(name_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:48:05.703141Z",
     "start_time": "2018-06-15T00:47:54.699623Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Use year 2016 as time -----\n",
    "path = '/OSM/CBR/OA_DCFP/data/model_output/CAFE/forecasts/v1/yr2016/mn1/OUTPUT.1/atmos_daily*.nc'\n",
    "dataset = xr.open_mfdataset(path, autoclose=True)\n",
    "time_use = xr.concat([dataset.time[:59], dataset.time[60:366]],dim='time')\n",
    "time_ly = dataset.time[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:49:54.610202Z",
     "start_time": "2018-06-15T00:48:05.706615Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Make month_day array of month-day -----\n",
    "m = [str(ds.time.values[i].timetuple()[1]).zfill(2) + '-' for i in range(len(ds.time))]\n",
    "d = [str(ds.time.values[i].timetuple()[2]).zfill(2) for i in range(len(ds.time))]\n",
    "md = np.core.defchararray.add(m, d)\n",
    "\n",
    "# Replace time array with month_day array and groupby -----\n",
    "ds['time'] = md\n",
    "clim = ds.groupby('time').mean(dim='time',keep_attrs=True)\n",
    "clim['time'] = time_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T00:49:54.840068Z",
     "start_time": "2018-06-15T00:49:54.613541Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Replicate Feb 28th as Feb 29th to deal with leap years -----\n",
    "clim_ly = clim.copy().sel(time='2016-02-28')\n",
    "clim_ly['time'] = np.array([time_ly.values])\n",
    "clim = xr.auto_combine([clim,clim_ly]).sortby('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-15T02:07:56.333437Z",
     "start_time": "2018-06-15T00:49:54.843145Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 28s, sys: 12min 55s, total: 57min 23s\n",
      "Wall time: 40min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save the climatology -----\n",
    "save_fldr = '/OSM/CBR/OA_DCFP/data/intermediate_products/doppyo/mean_climatologies/'\n",
    "clim.to_netcdf(save_fldr + 'cafe.c2.atmos.500_549.clim.new.nc', mode = 'w',\n",
    "               encoding = {'time':{'dtype':'float','calendar':'JULIAN',\n",
    "                           'units':'days since 0001-01-01 00:00:00'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:     (lat: 90, latb: 91, level: 37, lon: 144, lonb: 145, nv: 2, time: 366)\n",
       "Coordinates:\n",
       "  * lon         (lon) float64 1.25 3.75 6.25 8.75 11.25 13.75 16.25 18.75 ...\n",
       "  * lonb        (lonb) float64 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0 22.5 ...\n",
       "  * lat         (lat) float64 -89.49 -87.98 -85.96 -83.93 -81.91 -79.89 ...\n",
       "  * latb        (latb) float64 -90.0 -88.99 -86.97 -84.94 -82.92 -80.9 ...\n",
       "  * level       (level) float32 1.0 2.0 3.0 5.0 7.0 10.0 20.0 30.0 50.0 70.0 ...\n",
       "  * nv          (nv) float64 1.0 2.0\n",
       "  * time        (time) datetime64[ns] 2016-01-01T12:00:00 ...\n",
       "Data variables:\n",
       "    gh          (time, level, lat, lon) float32 dask.array<shape=(366, 37, 90, 144), chunksize=(366, 37, 90, 144)>\n",
       "    lwf         (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    shf         (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    tau_x       (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    tau_y       (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    t_ref       (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    q_ref       (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    u_ref       (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    v_ref       (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    t_s         (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    t_ref_min   (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    t_ref_max   (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    ps          (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    h500        (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    sphum       (time, level, lat, lon) float32 dask.array<shape=(366, 37, 90, 144), chunksize=(366, 37, 90, 144)>\n",
       "    temp        (time, level, lat, lon) float32 dask.array<shape=(366, 37, 90, 144), chunksize=(366, 37, 90, 144)>\n",
       "    u           (time, level, lat, lon) float32 dask.array<shape=(366, 37, 90, 144), chunksize=(366, 37, 90, 144)>\n",
       "    v           (time, level, lat, lon) float32 dask.array<shape=(366, 37, 90, 144), chunksize=(366, 37, 90, 144)>\n",
       "    precip      (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    lwf_dn_s    (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    olr         (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    swf_dn_s    (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    swf_up_toa  (time, lat, lon) float32 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>\n",
       "    zsurf       (time, lat, lon) float64 dask.array<shape=(366, 90, 144), chunksize=(366, 90, 144)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scratch_env]",
   "language": "python",
   "name": "conda-env-scratch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
